import cv2
import requests
import base64
import argparse
import os
from tqdm import tqdm
import numpy as np
import pandas as pd
# PILì€ í•œê¸€ ìë§‰ì—ë§Œ ì‚¬ìš©
from PIL import Image, ImageDraw, ImageFont
import textwrap
from translator.vertex_translate import translate_english_to_korean
from datetime import timedelta
import shutil
import csv

# --- ì„¤ì • ---
API_URL    = "http://127.0.0.1:9997/v1/chat/completions"
MODEL_NAME = "InternVL3"
MAX_TOKENS = 256

def parse_response(response_data: dict) -> str | None:
    try:
        return response_data["choices"][0]["message"]["content"].strip()
    except:
        return None

def wrap_text_cv(text, font, scale, thickness, max_width):
    # OpenCV ì „ìš© ì¤„ë°”ê¿ˆ
    words, lines, cur = text.split(' '), [], ''
    for w in words:
        test = f"{cur} {w}".strip()
        (tw, _), _ = cv2.getTextSize(test, font, scale, thickness)
        if tw <= max_width:
            cur = test
        else:
            if cur: lines.append(cur)
            cur = w
    if cur: lines.append(cur)
    return lines

def wrap_text_pil(text, font, max_width, spacing):
    """
    PIL ì´ë¯¸ì§€ ë“œë¡œì–´(draw)ë¥¼ ì“°ì§€ ì•Šê³ ë„
    ê¸€ì ë‹¨ìœ„ë¡œ ìµœëŒ€ í”½ì…€ ë„ˆë¹„ë¥¼ ë„˜ì§€ ì•Šê²Œ ì¤„ë°”ê¿ˆí•˜ëŠ” í•¨ìˆ˜.
    """
    words = text.split(' ')
    lines = []
    current = ''
    for w in words:
        test = f"{current} {w}".strip()
        # ì„ì‹œ ì´ë¯¸ì§€ë¡œ í¬ê¸° ì¬ê¸°
        tmp_img = Image.new("RGB", (1,1))
        tmp_draw = ImageDraw.Draw(tmp_img)
        bbox = tmp_draw.textbbox((0,0), test, font=font, spacing=spacing)
        width_px = bbox[2] - bbox[0]
        if width_px <= max_width:
            current = test
        else:
            if current:
                lines.append(current)
            current = w
    if current:
        lines.append(current)
    return lines

# def process_video(video_path: str, time_interval: int, question: str, lang: str = "en"):
#     cap    = cv2.VideoCapture(video_path)
#     fps    = cap.get(cv2.CAP_PROP_FPS)
#     width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
#     frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

#     out_path = f"{os.path.splitext(video_path)[0]}_subtitled.mp4"
#     fourcc   = cv2.VideoWriter_fourcc(*'mp4v')
#     out      = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

#     latest_sub = None
#     latest_sub_ko = None
#     # ê³µí†µ
#     max_w    = int(width * 0.8)
#     alpha_bg = 0.6

#     # ì˜ì–´(OpenCV) ì„¤ì •
#     font_cv    = cv2.FONT_HERSHEY_SIMPLEX
#     scale_cv   = 1.0
#     thick_cv   = 2
#     line_sp_cv = 10

#     # í•œê¸€(PIL) ì„¤ì •
#     # NanumGothic.ttf ê°™ì€ í•œê¸€ í°íŠ¸ íŒŒì¼ì„ í”„ë¡œì íŠ¸ ê²½ë¡œì— ë‘ì„¸ìš”
#     pil_font = ImageFont.truetype("NanumGothic.ttf", 32)
#     line_sp_pil = 4

#     for i in tqdm(range(frames), desc="ì²˜ë¦¬ ì¤‘"):
#         ret, frame = cap.read()
#         if not ret:
#             break

#         # 1) ì¼ì • ê°„ê²©ë§ˆë‹¤ API í˜¸ì¶œ
#         if i % time_interval == 0:
#             success, buf = cv2.imencode('.jpg', frame)
#             if success:
#                 b64 = base64.b64encode(buf).decode()
#                 payload = {
#                     "model": MODEL_NAME,
#                     "messages": [{
#                         "role": "user",
#                         "content": [
#                             {"type": "text", "text": f"<image>\n{question}"},
#                             {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}}
#                         ]
#                     }],
#                     "max_tokens": MAX_TOKENS
#                 }
#                 try:
#                     r = requests.post(API_URL, json=payload, timeout=30)
#                     if r.status_code == 200:
#                         sub = parse_response(r.json())
#                         if sub and sub != latest_sub:
#                             latest_sub = sub
#                             if lang == "kor":
#                                 latest_sub_ko = translate_english_to_korean(latest_sub)
#                 except:
#                     pass

#         # 2) ìº¡ì…˜ ê·¸ë¦¬ê¸°
#         if latest_sub:
#             if lang == 'en':
#                 # --- ì˜ì–´: OpenCV ë¡œ ê·¸ë¦¬ê¸° ---
#                 lines = wrap_text_cv(latest_sub, font_cv, scale_cv, thick_cv, max_w)
#                 sizes = [cv2.getTextSize(line, font_cv, scale_cv, thick_cv)[0] for line in lines]
#                 bw = max(w for w, h in sizes)
#                 bh = sum(h for w, h in sizes) + line_sp_cv*(len(lines)-1)

#                 x1 = (width - bw)//2 - 10
#                 y1 = height - bh - 30
#                 x2, y2 = x1 + bw + 20, y1 + bh + 20

#                 overlay = frame.copy()
#                 cv2.rectangle(overlay, (x1,y1), (x2,y2), (0,0,0), -1)
#                 cv2.addWeighted(overlay, alpha_bg, frame, 1-alpha_bg, 0, frame)

#                 y = y1 + 10 + sizes[0][1]
#                 for (w, h), line in zip(sizes, lines):
#                     x = (width - w)//2
#                     cv2.putText(frame, line, (x, y), font_cv, scale_cv, (255,255,255), thick_cv, cv2.LINE_AA)
#                     y += h + line_sp_cv

#             elif lang == "kor":
#                 text = latest_sub_ko
#                 # 1) Frame â†’ PIL
#                 img_pil = Image.fromarray(frame).convert("RGBA")
#                 draw    = ImageDraw.Draw(img_pil)

#                 # 2) ë²ˆì—­ (í•„ìš” ì‹œ) + ì¤„ë°”ê¿ˆ
#                 lines  = wrap_text_pil(text, pil_font, max_w, line_sp_pil)
                
#                 # 3) í…ìŠ¤íŠ¸ ë¸”ë¡ í¬ê¸° ê³„ì‚°
#                 # multiline_textbbox ë¡œ ì „ì²´ ë°•ìŠ¤ ì¸¡ì •
#                 text_block = "\n".join(lines)
#                 bbox = draw.multiline_textbbox((0,0), text_block, font=pil_font, spacing=line_sp_pil)
#                 tw = bbox[2] - bbox[0]
#                 th = bbox[3] - bbox[1]

#                 # 4) ìœ„ì¹˜ ê³„ì‚° (í•˜ë‹¨ ì¤‘ì•™)
#                 x = (width - tw)//2
#                 y = height - th - 30

#                 # 5) ë°˜íˆ¬ëª… ë°°ê²½
#                 overlay = Image.new("RGBA", img_pil.size, (0,0,0,0))
#                 bg = Image.new("RGBA", (tw+20, th+20), (0,0,0, int(255*alpha_bg)))
#                 overlay.paste(bg, (x-10, y-10))
#                 img_pil = Image.alpha_composite(img_pil, overlay)

#                 # 6) í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
#                 draw = ImageDraw.Draw(img_pil)
#                 draw.multiline_text((x, y), text_block,
#                                     font=pil_font,
#                                     fill=(255,255,255,255),
#                                     spacing=line_sp_pil,
#                                     align="center")

#                 # 7) PIL â†’ numpy
#                 frame = np.array(img_pil.convert("RGB"))

#         out.write(frame)

#     cap.release()
#     out.release()
#     print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {out_path}")

def process_video(video_path: str, time_interval: int, question: str, lang: str = "en"):
    cap    = cv2.VideoCapture(video_path)
    fps    = cap.get(cv2.CAP_PROP_FPS)
    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    save_dir = "/tmp/vqa_video_result"
    os.makedirs(save_dir, exist_ok=True)

    base_name = os.path.splitext(os.path.basename(video_path))[0]

    # ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
    out_path = os.path.join(save_dir, f"{base_name}_subtitled_only_descrition.mp4")
    fourcc   = cv2.VideoWriter_fourcc(*'mp4v')
    out      = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

    # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸ (DataFrameìœ¼ë¡œ ë³€í™˜)
    records = []

    latest_sub = None
    latest_sub_ko = None
    max_w    = int(width * 0.8)
    alpha_bg = 0.6

    # ì˜ì–´ í°íŠ¸ ì„¤ì • (OpenCV)
    font_cv    = cv2.FONT_HERSHEY_SIMPLEX
    scale_cv   = 1.0
    thick_cv   = 2
    line_sp_cv = 10

    # í•œê¸€ í°íŠ¸ ì„¤ì • (PIL)
    pil_font = ImageFont.truetype("NanumGothic.ttf", 32)
    line_sp_pil = 4

    for i in tqdm(range(frames), desc="ì²˜ë¦¬ ì¤‘"):
        ret, frame = cap.read()
        if not ret:
            break

        if i % time_interval == 0:
            success, buf = cv2.imencode('.jpg', frame)
            if success:
                b64 = base64.b64encode(buf).decode()
                payload = {
                    "model": MODEL_NAME,
                    "messages": [{
                        "role": "user",
                        "content": [
                            {"type": "text", "text": f"<image>\n{question}"},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}}
                        ]
                    }],
                    "max_tokens": MAX_TOKENS
                }
                try:
                    r = requests.post(API_URL, json=payload, timeout=30)
                    if r.status_code == 200:
                        sub = parse_response(r.json())
                        if sub and sub != latest_sub:
                            latest_sub = sub
                            if lang == "kor":
                                latest_sub_ko = translate_english_to_korean(latest_sub)

                            # ì‹œê°„ ê³„ì‚°
                            sec = i / fps
                            time_str = str(timedelta(seconds=sec))[:10]

                            # ê²°ê³¼ ê¸°ë¡
                            records.append({
                                "frame": i,
                                "time": time_str,
                                "description": sub
                            })

                            # ğŸ”¥ í”„ë ˆì„ ì´ë¯¸ì§€ ì €ì¥
                            frame_img_path = os.path.join(save_dir, f"{base_name}_{i}.jpg")
                            cv2.imwrite(frame_img_path, frame)

                except Exception as e:
                    print(f"[ERROR] Frame {i}: {e}")
                    pass

        # ìë§‰ ë Œë”ë§
        if latest_sub:
            if lang == 'en':
                lines = wrap_text_cv(latest_sub, font_cv, scale_cv, thick_cv, max_w)
                sizes = [cv2.getTextSize(line, font_cv, scale_cv, thick_cv)[0] for line in lines]
                bw = max(w for w, h in sizes)
                bh = sum(h for w, h in sizes) + line_sp_cv*(len(lines)-1)

                x1 = (width - bw)//2 - 10
                y1 = height - bh - 30
                x2, y2 = x1 + bw + 20, y1 + bh + 20

                overlay = frame.copy()
                cv2.rectangle(overlay, (x1,y1), (x2,y2), (0,0,0), -1)
                cv2.addWeighted(overlay, alpha_bg, frame, 1-alpha_bg, 0, frame)

                y = y1 + 10 + sizes[0][1]
                for (w, h), line in zip(sizes, lines):
                    x = (width - w)//2
                    cv2.putText(frame, line, (x, y), font_cv, scale_cv, (255,255,255), thick_cv, cv2.LINE_AA)
                    y += h + line_sp_cv

            elif lang == "kor":
                text = latest_sub_ko
                img_pil = Image.fromarray(frame).convert("RGBA")
                draw    = ImageDraw.Draw(img_pil)

                lines = wrap_text_pil(text, pil_font, max_w, line_sp_pil)
                text_block = "\n".join(lines)
                bbox = draw.multiline_textbbox((0,0), text_block, font=pil_font, spacing=line_sp_pil)
                tw = bbox[2] - bbox[0]
                th = bbox[3] - bbox[1]

                x = (width - tw)//2
                y = height - th - 30

                overlay = Image.new("RGBA", img_pil.size, (0,0,0,0))
                bg = Image.new("RGBA", (tw+20, th+20), (0,0,0, int(255*alpha_bg)))
                overlay.paste(bg, (x-10, y-10))
                img_pil = Image.alpha_composite(img_pil, overlay)

                draw = ImageDraw.Draw(img_pil)
                draw.multiline_text((x, y), text_block,
                                    font=pil_font,
                                    fill=(255,255,255,255),
                                    spacing=line_sp_pil,
                                    align="center")

                frame = np.array(img_pil.convert("RGB"))

        out.write(frame)

    cap.release()
    out.release()

    # âœ… CSV ì €ì¥
    df = pd.DataFrame(records)
    csv_path = os.path.join(save_dir, f"{base_name}_subtitled_only_descrition.csv")
    df.to_csv(csv_path, index=False, encoding='utf-8-sig')

    # âœ… ì›ë³¸ ë¹„ë””ì˜¤ ë³µì‚¬
    shutil.copy(video_path, os.path.join(save_dir, os.path.basename(video_path)))

    print(f"\nâœ… ìë§‰ ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {out_path}")
    print(f"ğŸ“„ CSV ì €ì¥ ì™„ë£Œ: {csv_path}")
    # âœ… ì›ë˜ ë¹„ë””ì˜¤ í´ë”ë¡œ ë³µì‚¬
    shutil.copy(out_path, os.path.join(os.path.dirname(video_path), os.path.basename(out_path)))
    shutil.copy(csv_path, os.path.join(os.path.dirname(video_path), os.path.basename(csv_path)))
