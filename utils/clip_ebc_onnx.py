import os
import sys
import torch
import numpy as np
import onnxruntime as ort
from typing import Union, Tuple, Optional
from PIL import Image
import matplotlib.pyplot as plt
from torchvision.transforms import ToTensor, Normalize
from torchvision.transforms.functional import normalize, to_pil_image
import json
import datetime
from scipy.ndimage import gaussian_filter
from sklearn.cluster import KMeans
import assets

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

class ClipEBCOnnx:
    """
    CLIP-EBC (Efficient Boundary Counting) ONNX ë²„ì „ ì´ë¯¸ì§€ ì²˜ë¦¬ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    
    ONNXë¡œ ë³€í™˜ëœ CLIP ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ë©°, ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì˜ˆì¸¡ ê¸°ëŠ¥ì„ í¬í•¨í•œ
    ë‹¤ì–‘í•œ ì„¤ì • ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    def __init__(self,
                 onnx_model_path="assets/CLIP_EBC_nwpu_rmse_onnx.onnx",
                 truncation=4,
                 reduction=8,
                 granularity="fine",
                 anchor_points="average",
                 input_size=224,
                 window_size=224,
                 stride=224,
                 dataset_name="qnrf",
                 mean=(0.485, 0.456, 0.406),
                 std=(0.229, 0.224, 0.225),
                 config_dir="configs"):
        """CLIPEBC ONNX í´ë˜ìŠ¤ë¥¼ ì„¤ì • ë§¤ê°œë³€ìˆ˜ì™€ í•¨ê»˜ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.onnx_model_path = onnx_model_path
        self.truncation = truncation
        self.reduction = reduction
        self.granularity = granularity
        self.anchor_points_type = anchor_points
        self.input_size = input_size
        self.window_size = window_size
        self.stride = stride
        self.dataset_name = dataset_name
        self.mean = mean
        self.std = std
        self.config_dir = config_dir
        
        # ê²°ê³¼ ì €ì¥ìš© ë³€ìˆ˜ ì´ˆê¸°í™”
        self.density_map = None
        self.processed_image = None
        self.count = None
        self.original_image = None
        
        # ONNX ì¶”ë¡  ì„¸ì…˜ ì„¤ì •
        self.session_options = ort.SessionOptions()
        self.session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        
        # ê°€ëŠ¥í•œ ê²½ìš° GPU ì‚¬ìš©
        self.providers = []
        if 'CUDAExecutionProvider' in ort.get_available_providers():
            self.providers.append('CUDAExecutionProvider')
        self.providers.append('CPUExecutionProvider')
        
        # ONNX ëŸ°íƒ€ì„ ì„¸ì…˜ ì´ˆê¸°í™”
        print(f"ONNX ëª¨ë¸ ë¡œë“œ ì¤‘: {self.onnx_model_path}")
        self.session = ort.InferenceSession(
            self.onnx_model_path, 
            sess_options=self.session_options,
            providers=self.providers
        )
        
        # ëª¨ë¸ì˜ ì…ë ¥ ë° ì¶œë ¥ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        self.input_name = self.session.get_inputs()[0].name
        self.output_name = self.session.get_outputs()[0].name
        
        print(f"ì…ë ¥ ì´ë¦„: {self.input_name}, í˜•íƒœ: {self.session.get_inputs()[0].shape}")
        print(f"ì¶œë ¥ ì´ë¦„: {self.output_name}, í˜•íƒœ: {self.session.get_outputs()[0].shape}")
        print(f"ì‹¤í–‰ ì œê³µì: {self.providers}")
        
    def _process_image(self, image: Union[str, np.ndarray]) -> np.ndarray:
        """
        ì´ë¯¸ì§€ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ ê²½ë¡œ, ë„˜íŒŒì´ ë°°ì—´, Streamlit UploadedFile ëª¨ë‘ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€. ë‹¤ìŒ í˜•ì‹ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤:
                - str: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
                - np.ndarray: (H, W, 3) í˜•íƒœì˜ RGB ì´ë¯¸ì§€
                - UploadedFile: Streamlitì˜ ì—…ë¡œë“œëœ íŒŒì¼
                    
        Returns:
            np.ndarray: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ë°°ì—´, shape (1, 3, H, W)
        """
        to_tensor = ToTensor()
        normalize = Normalize(mean=self.mean, std=self.std)
        
        # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
        self.original_image = image
        
        # ì…ë ¥ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
        if isinstance(image, str):
            # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
            with open(image, "rb") as f:
                pil_image = Image.open(f).convert("RGB")
        elif isinstance(image, np.ndarray):
            # ë„˜íŒŒì´ ë°°ì—´ì¸ ê²½ìš°
            if image.dtype == np.uint8:
                pil_image = Image.fromarray(image)
            else:
                # float íƒ€ì…ì¸ ê²½ìš° [0, 1] ë²”ìœ„ë¡œ ê°€ì •í•˜ê³  ë³€í™˜
                pil_image = Image.fromarray((image * 255).astype(np.uint8))
        else:
            # Streamlit UploadedFile ë˜ëŠ” ê¸°íƒ€ íŒŒì¼ ê°ì²´ì¸ ê²½ìš°
            try:
                pil_image = Image.open(image).convert("RGB")
            except Exception as e:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤: {type(image)}") from e
        
        # í…ì„œ ë³€í™˜ ë° ì •ê·œí™”
        tensor_image = to_tensor(pil_image)
        normalized_image = normalize(tensor_image)
        batched_image = normalized_image.unsqueeze(0)  # (1, 3, H, W)
        
        # numpyë¡œ ë³€í™˜
        numpy_image = batched_image.numpy()
        
        return numpy_image
    
    def _post_process_image(self, image_tensor):
        """ì´ë¯¸ì§€ í…ì„œë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        # NumPy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜
        if isinstance(image_tensor, np.ndarray):
            image_tensor = torch.from_numpy(image_tensor)
            
        # ì •ê·œí™” ì—­ë³€í™˜
        image = normalize(
            image_tensor,
            mean=[0., 0., 0.],
            std=[1./self.std[0], 1./self.std[1], 1./self.std[2]]
        )
        
        image = normalize(
            image,
            mean=[-self.mean[0], -self.mean[1], -self.mean[2]],
            std=[1., 1., 1.]
        )
        
        # ë°°ì¹˜ ì°¨ì› ì œê±° ë° PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        processed_image = to_pil_image(image.squeeze(0))
        return processed_image

    def sliding_window_predict(self, image: np.ndarray, window_size: Union[int, Tuple[int, int]], 
                             stride: Union[int, Tuple[int, int]]) -> np.ndarray:
        """
        ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ê²¹ì¹˜ëŠ” ì˜ì—­ì€ í‰ê· ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        
        Args:
            image (np.ndarray): í˜•íƒœê°€ (1, 3, H, W)ì¸ ì´ë¯¸ì§€ ë°°ì—´
            window_size (int or tuple): ìœˆë„ìš° í¬ê¸°
            stride (int or tuple): ìœˆë„ìš° ì´ë™ ê°„ê²©
            
        Returns:
            np.ndarray: ì˜ˆì¸¡ëœ ë°€ë„ ë§µ
        """
        # ì…ë ¥ ê²€ì¦
        assert len(image.shape) == 4, f"ì´ë¯¸ì§€ëŠ” 4ì°¨ì› ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤. (1, C, H, W), í˜„ì¬: {image.shape}"
        
        # ìœˆë„ìš° í¬ê¸°ì™€ ìŠ¤íŠ¸ë¼ì´ë“œ ì„¤ì •
        window_size = (int(window_size), int(window_size)) if isinstance(window_size, (int, float)) else window_size
        stride = (int(stride), int(stride)) if isinstance(stride, (int, float)) else stride
        window_size = tuple(window_size)
        stride = tuple(stride)
        
        # ê²€ì¦
        assert isinstance(window_size, tuple) and len(window_size) == 2 and window_size[0] > 0 and window_size[1] > 0, \
            f"ìœˆë„ìš° í¬ê¸°ëŠ” ì–‘ìˆ˜ ì •ìˆ˜ íŠœí”Œ (h, w)ì´ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {window_size}"
        assert isinstance(stride, tuple) and len(stride) == 2 and stride[0] > 0 and stride[1] > 0, \
            f"ìŠ¤íŠ¸ë¼ì´ë“œëŠ” ì–‘ìˆ˜ ì •ìˆ˜ íŠœí”Œ (h, w)ì´ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {stride}"
        assert stride[0] <= window_size[0] and stride[1] <= window_size[1], \
            f"ìŠ¤íŠ¸ë¼ì´ë“œëŠ” ìœˆë„ìš° í¬ê¸°ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {stride}ì™€ {window_size}"
        
        image_height, image_width = image.shape[-2:]
        window_height, window_width = window_size
        stride_height, stride_width = stride
        
        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ìˆ˜ ê³„ì‚°
        num_rows = int(np.ceil((image_height - window_height) / stride_height) + 1)
        num_cols = int(np.ceil((image_width - window_width) / stride_width) + 1)
        
        # ìœˆë„ìš° ì¶”ì¶œ
        windows = []
        window_positions = []
        for i in range(num_rows):
            for j in range(num_cols):
                x_start, y_start = i * stride_height, j * stride_width
                x_end, y_end = x_start + window_height, y_start + window_width
                
                # ì´ë¯¸ì§€ ê²½ê³„ ì²˜ë¦¬
                if x_end > image_height:
                    x_start, x_end = image_height - window_height, image_height
                if y_end > image_width:
                    y_start, y_end = image_width - window_width, image_width
                
                window = image[:, :, x_start:x_end, y_start:y_end]
                windows.append(window)
                window_positions.append((x_start, y_start, x_end, y_end))
        
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì¶”ë¡ 
        all_preds = []
        max_batch_size = 8
        
        for start_idx in range(0, len(windows), max_batch_size):
            end_idx = min(start_idx + max_batch_size, len(windows))
            batch_windows = np.vstack(windows[start_idx:end_idx])  # (batch_size, 3, h, w)
            
            # ONNX ì¶”ë¡ 
            ort_inputs = {self.input_name: batch_windows}
            batch_preds = self.session.run([self.output_name], ort_inputs)[0]
            
            # Debug ì •ë³´
            # print(f"ë°°ì¹˜ ì…ë ¥ í˜•íƒœ: {batch_windows.shape}, ë°°ì¹˜ ì¶œë ¥ í˜•íƒœ: {batch_preds.shape}")
            
            all_preds.extend([batch_preds[i:i+1] for i in range(batch_preds.shape[0])])
        
        # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        preds = np.concatenate(all_preds, axis=0)
        
        # ì¶œë ¥ ë°€ë„ ë§µ ì¡°ë¦½
        pred_map = np.zeros((preds.shape[1], image_height // self.reduction, image_width // self.reduction), dtype=np.float32)
        count_map = np.zeros((preds.shape[1], image_height // self.reduction, image_width // self.reduction), dtype=np.float32)
        
        idx = 0
        for i in range(num_rows):
            for j in range(num_cols):
                x_start, y_start, x_end, y_end = window_positions[idx]
                
                # ì¶œë ¥ ì˜ì—­ ê³„ì‚° (reduction ê³ ë ¤)
                x_start_out = x_start // self.reduction
                y_start_out = y_start // self.reduction
                x_end_out = x_end // self.reduction
                y_end_out = y_end // self.reduction
                
                pred_map[:, x_start_out:x_end_out, y_start_out:y_end_out] += preds[idx]
                count_map[:, x_start_out:x_end_out, y_start_out:y_end_out] += 1.
                idx += 1
        
        # ê²¹ì¹˜ëŠ” ì˜ì—­ í‰ê·  ê³„ì‚°
        pred_map /= count_map
        
        return pred_map

    def resize_density_map(self, density_map: np.ndarray, target_size: Tuple[int, int]) -> np.ndarray:
        """
        ë°€ë„ ë§µì˜ í¬ê¸°ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤. ì´í•©ì€ ë³´ì¡´ë©ë‹ˆë‹¤.
        
        Args:
            density_map: í˜•íƒœê°€ (C, H, W)ì¸ ë°€ë„ ë§µ
            target_size: ëª©í‘œ í¬ê¸° (H', W')
            
        Returns:
            np.ndarray: í¬ê¸°ê°€ ì¡°ì •ëœ ë°€ë„ ë§µ
        """
        from PIL import Image
        import torch.nn.functional as F
        import torch
        
        # numpyë¥¼ torchë¡œ ë³€í™˜
        if isinstance(density_map, np.ndarray):
            density_map = torch.from_numpy(density_map)
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        if density_map.dim() == 3:
            density_map = density_map.unsqueeze(0)  # (1, C, H, W)
        
        current_size = density_map.shape[2:]
        
        if current_size[0] == target_size[0] and current_size[1] == target_size[1]:
            return density_map.squeeze(0).numpy()
        
        # ì›ë³¸ ë°€ë„ ë§µì˜ ì´í•© ê³„ì‚°
        original_sum = density_map.sum()
        
        # í¬ê¸° ì¡°ì • (ìŒì„ í˜• ë³´ê°„)
        resized_map = F.interpolate(
            density_map,
            size=target_size,
            mode='bilinear',
            align_corners=False
        )
        
        # ì´í•© ë³´ì¡´ì„ ìœ„í•œ ìŠ¤ì¼€ì¼ë§
        if resized_map.sum() > 0:  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
            resized_map = resized_map * (original_sum / resized_map.sum())
        
        return resized_map.squeeze(0).numpy()

    def predict(self, image: Union[str, np.ndarray]) -> float:
        """
        ì´ë¯¸ì§€ì—ì„œ êµ°ì¤‘ ê³„ìˆ˜ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (ê²½ë¡œ, ë„˜íŒŒì´ ë°°ì—´, ë˜ëŠ” ì—…ë¡œë“œëœ íŒŒì¼)
            
        Returns:
            float: ì˜ˆì¸¡ëœ ì‚¬ëŒ ìˆ˜
        """
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        processed_image = self._process_image(image)
        image_height, image_width = processed_image.shape[-2:]
        
        
        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì˜ˆì¸¡
        pred_density = self.sliding_window_predict(
            processed_image, 
            self.window_size, 
            self.stride
        )
        
        # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
        pred_count = pred_density.sum()
        
        # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë°€ë„ ë§µ ì¡°ì •
        resized_pred_density = self.resize_density_map(
            pred_density, 
            (image_height, image_width)
        )
        
        # ê²°ê³¼ ì €ì¥
        self.processed_image = self._post_process_image(processed_image)
        self.density_map = resized_pred_density.squeeze()
        self.count = pred_count
        
        return pred_count
    
    def visualize_density_map(self, alpha: float = 0.5, save: bool = False, 
                            save_path: Optional[str] = None):
        """
        í˜„ì¬ ì €ì¥ëœ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
        
        Args:
            alpha (float): density mapì˜ íˆ¬ëª…ë„ (0~1). ê¸°ë³¸ê°’ 0.5
            save (bool): ì‹œê°í™” ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€. ê¸°ë³¸ê°’ False
            save_path (str, optional): ì €ì¥í•  ê²½ë¡œ. Noneì¼ ê²½ìš° í˜„ì¬ ë””ë ‰í† ë¦¬ì— ìë™ ìƒì„±ëœ ì´ë¦„ìœ¼ë¡œ ì €ì¥.
                ê¸°ë³¸ê°’ None
                
        Returns:
            Tuple[matplotlib.figure.Figure, np.ndarray]:
                - density mapì´ ì˜¤ë²„ë ˆì´ëœ matplotlib Figure ê°ì²´
                - RGB í˜•ì‹ì˜ ì‹œê°í™”ëœ ì´ë¯¸ì§€ ë°°ì—´ (H, W, 3)
        """
        if self.density_map is None or self.processed_image is None:
            raise ValueError("ë¨¼ì € predict ë©”ì„œë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        fig, ax = plt.subplots(dpi=200, frameon=False)
        ax.imshow(self.processed_image)
        ax.imshow(self.density_map, cmap="jet", alpha=alpha)
        ax.axis("off")
        plt.title(f"Count: {self.count:.1f}")
        
        if save:
            if save_path is None:
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                save_path = f"crowd_density_{timestamp}.png"
            
            # ì—¬ë°± ì œê±°í•˜ê³  ì €ì¥
            plt.savefig(save_path, bbox_inches='tight', pad_inches=0, dpi=200)
            print(f"ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}")
        
        fig.canvas.draw()
        image_from_plot = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)
        image_from_plot = image_from_plot.reshape(fig.canvas.get_width_height()[::-1] + (4,))
        image_from_plot = image_from_plot[:,:,:3]  # RGBë¡œ ë³€í™˜
        
        return fig, image_from_plot
    
    def visualize_dots(self, dot_size: int = 20, sigma: float = 1, percentile: float = 97, 
                    save: bool = False, save_path: Optional[str] = None):
        """
        ì˜ˆì¸¡ëœ êµ°ì¤‘ ìœ„ì¹˜ë¥¼ ì ìœ¼ë¡œ í‘œì‹œí•˜ì—¬ ì‹œê°í™”í•©ë‹ˆë‹¤.
        
        Args:
            dot_size (int): ì ì˜ í¬ê¸°. ê¸°ë³¸ê°’ 20
            sigma (float): Gaussian í•„í„°ì˜ sigma ê°’. ê¸°ë³¸ê°’ 1
            percentile (float): ì„ê³„ê°’ìœ¼ë¡œ ì‚¬ìš©í•  ë°±ë¶„ìœ„ìˆ˜ (0-100). ê¸°ë³¸ê°’ 97
            save (bool): ì‹œê°í™” ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€. ê¸°ë³¸ê°’ False
            save_path (str, optional): ì €ì¥í•  ê²½ë¡œ. Noneì¼ ê²½ìš° í˜„ì¬ ë””ë ‰í† ë¦¬ì— ìë™ ìƒì„±ëœ ì´ë¦„ìœ¼ë¡œ ì €ì¥.
                ê¸°ë³¸ê°’ None
                
        Returns:
            Tuple[matplotlib.backends.backend_agg.FigureCanvasBase, np.ndarray]: 
                - matplotlib figureì˜ canvas ê°ì²´
                - RGB í˜•ì‹ì˜ ì‹œê°í™”ëœ ì´ë¯¸ì§€ ë°°ì—´ (H, W, 3)
        """
        if self.density_map is None or self.processed_image is None:
            raise ValueError("ë¨¼ì € predict ë©”ì„œë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")
            
        adjusted_pred_count = int(round(self.count))
        
        if adjusted_pred_count == 0:
            print("ğŸ’¡ ì˜ˆì¸¡ëœ êµ°ì¤‘ ìˆ˜ê°€ 0ì…ë‹ˆë‹¤. dot ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None, None

        fig, ax = plt.subplots(dpi=200, frameon=False)
        ax.imshow(self.processed_image)
        
        filtered_density = gaussian_filter(self.density_map, sigma=sigma)
        
        threshold = np.percentile(filtered_density, percentile)
        candidate_pixels = np.column_stack(np.where(filtered_density >= threshold))
        
        if len(candidate_pixels) > adjusted_pred_count:
            kmeans = KMeans(n_clusters=adjusted_pred_count, random_state=42, n_init=10)
            kmeans.fit(candidate_pixels)
            head_positions = kmeans.cluster_centers_.astype(int)
        else:
            head_positions = candidate_pixels
            
        y_coords, x_coords = head_positions[:, 0], head_positions[:, 1]
        ax.scatter(x_coords, y_coords, 
                    c='red',
                    s=dot_size,
                    alpha=1.0,
                    edgecolors='white',
                    linewidth=1)
        
        ax.axis("off")
        plt.title(f"Count: {self.count:.1f}")
        
        if save:
            if save_path is None:
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                save_path = f"crowd_dots_{timestamp}.png"
            
            plt.savefig(save_path, bbox_inches='tight', pad_inches=0, dpi=200)
            print(f"ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}")
        
        # Figureë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        fig.canvas.draw()
        image_from_plot = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)
        image_from_plot = image_from_plot.reshape(fig.canvas.get_width_height()[::-1] + (4,))
        image_from_plot = image_from_plot[:,:,:3]  # RGBë¡œ ë³€í™˜
        
        return fig.canvas, image_from_plot
    
    def crowd_count(self):
        """
        ê°€ì¥ ìµœê·¼ ì˜ˆì¸¡ì˜ êµ°ì¤‘ ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            float: ì˜ˆì¸¡ëœ êµ°ì¤‘ ìˆ˜
            None: ì•„ì§ ì˜ˆì¸¡ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì€ ê²½ìš°
        """
        return self.count
    
    def get_density_map(self):
        """
        ê°€ì¥ ìµœê·¼ ì˜ˆì¸¡ì˜ ë°€ë„ ë§µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            numpy.ndarray: ë°€ë„ ë§µ
            None: ì•„ì§ ì˜ˆì¸¡ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì€ ê²½ìš°
        """
        return self.density_map